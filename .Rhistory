# Linear discriminant analysis correctly predicts the direction of the market
# 62.5% of the time.
### Part F
qda.fit <- qda(Direction ~ Lag2, data = weekly, subset = train)
qda.fit
qda.class <- predict(qda.fit, weekly.2008)$class
table(qda.class, Direction.2008)
mean(qda.class == Direction.2008)
# Quadratic discriminant analysis correctly predicts the direction of the market
# 58.7% of the time; however, it incorrectly predicts when the market goes down
# in every test case.
### Part G
# Create matrix of predictors for train and test data and vector of responses for
# training data
train.X <- as.matrix(weekly[train, ]$Lag2)
test.X <- as.matrix(weekly.2008$Lag2)
train.Direction <- Direction[train]
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Direction.2008)
mean(knn.pred == Direction.2008)
# KNN when k = 1 predicts the direction of the market correctly 50% of the time.
### Part H
nb.fit <- naiveBayes(Direction ~ Lag2, data = weekly, subset = train)
nb.fit
nb.class <- predict(nb.fit, weekly.2008)
table(nb.class, Direction.2008)
mean(nb.class == Direction.2008)
# Naive Bayes correctly predicts the direction of the market
# 58.7% of the time; however, it incorrectly predicts when the market goes down
# in every test case.
### Part I
results <- data.frame(algorithm = c("Logistic", "LDA", "QDA", "KNN", "Naive Bayes"),
accuracy = c(mean(test.pred == Direction.2008),
mean(lda.class == Direction.2008),
mean(qda.class == Direction.2008),
mean(knn.pred == Direction.2008),
mean(nb.class == Direction.2008)))
results
glm.j <- glm(
Direction ~ Lag1 + Lag2, data = weekly, family = binomial, subset = train)
test.probs.j <- predict(glm.train, weekly.2008, type = "response")
test.pred.j <- rep("Down", 104)
test.pred.j[test.probs > 0.5] <- "Up"
table(test.pred.j, Direction.2008)
mean(test.pred.j == Direction.2008)
glm.int.j<- glm(
Direction ~ Lag1 + Lag2, data = weekly, family = binomial, subset = train)
test.probs.int.j <- predict(glm.train, weekly.2008, type = "response")
test.pred.int.j <- rep("Down", 104)
test.pred.int.j[test.probs > 0.5] <- "Up"
table(test.pred.int.j, Direction.2008)
glm.int.j<- glm(
Direction ~ Lag1 * Lag2, data = weekly, family = binomial, subset = train)
test.probs.int.j <- predict(glm.train, weekly.2008, type = "response")
test.pred.int.j <- rep("Down", 104)
test.pred.int.j[test.probs > 0.5] <- "Up"
table(test.pred.int.j, Direction.2008)
mean(test.pred.int.j == Direction.2008)
glm.int.j<- glm(
Direction ~ Lag1 * Lag2 * Lag3 * Lag4 * Lag5, data = weekly, family = binomial, subset = train)
test.probs.int.j <- predict(glm.train, weekly.2008, type = "response")
test.pred.int.j <- rep("Down", 104)
test.pred.int.j[test.probs > 0.5] <- "Up"
table(test.pred.int.j, Direction.2008)
mean(test.pred.int.j == Direction.2008)
glm.int.j<- glm(
Direction ~ Lag1 * Lag2 * Lag3, data = weekly, family = binomial, subset = train)
test.probs.int.j <- predict(glm.train, weekly.2008, type = "response")
test.pred.int.j <- rep("Down", 104)
test.pred.int.j[test.probs > 0.5] <- "Up"
table(test.pred.int.j, Direction.2008)
mean(test.pred.int.j == Direction.2008)
lda.fit.j <- lda(Direction ~ I(Lag2^2), data = weekly, subset = train)
lda.fit.j
lda.pred.j <- predict(lda.fit.j, weekly.2008)
lda.class.j <- lda.pred.j$class
table(lda.class.j, Direction.2008)
mean(lda.class.j == Direction.2008)
qda.fit.j <- qda(Direction ~ I(Lag2^2), data = weekly, subset = train)
qda.fit.j
qda.class.j <- predict(qda.fit.j, weekly.2008)$class
table(qda.class.j, Direction.2008)
mean(qda.class.j == Direction.2008)
set.seed(4)
knn.pred <- knn(train.X, test.X, train.Direction, k = 3)
table(knn.pred, Direction.2008)
mean(knn.pred == Direction.2008)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(MASS)
library(e1071)
library(class)
weekly <- Weekly
View(weekly)
# Get names of columns in weekly dataset
names(weekly)
# get dimensions of the Weekly dataset
dim(weekly)
# Produce summary statistics for each column
summary(weekly)
# Get correlation matrix for weekly data
weekly_cor <- cor(weekly[, -9])
View(weekly_cor)
attach(weekly)
plot(Volume)
attach(weekly)
plot(Year, Volume)
# Create logistic regression with Direction as target and all other variables as
# predictors
glm.weekly <- glm(
Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume,
data = weekly, family = binomial
)
summary(glm.weekly)
weekly.probs <- predict(glm.weekly, type = "response")
weekly.pred <- rep("Down", 1089)
weekly.pred[weekly.probs > 0.5] = "Up"
table(weekly.pred, Direction)
mean(weekly.pred == Direction)
# Create a set of test data from the weekly dataset that includes observations
# from 2009 to 2010.
train <- (Year < 2009)
weekly.2008 <- weekly[!train, ]
dim(weekly.2008)
Direction.2008 <- Direction[!train]
glm.train <- glm(
Direction ~ Lag2, data = weekly, family = binomial, subset = train)
test.probs <- predict(glm.train, weekly.2008, type = "response")
test.pred <- rep("Down", 104)
test.pred[test.probs > 0.5] <- "Up"
table(test.pred, Direction.2008)
mean(test.pred == Direction.2008)
lda.fit <- lda(Direction ~ Lag2, data = weekly, subset = train)
lda.fit
lda.pred <- predict(lda.fit, weekly.2008)
lda.class <- lda.pred$class
table(lda.class, Direction.2008)
mean(lda.class == Direction.2008)
qda.fit <- qda(Direction ~ Lag2, data = weekly, subset = train)
qda.fit
qda.class <- predict(qda.fit, weekly.2008)$class
table(qda.class, Direction.2008)
mean(qda.class == Direction.2008)
# Create matrix of predictors for train and test data and vector of responses for
# training data
train.X <- as.matrix(weekly[train, ]$Lag2)
test.X <- as.matrix(weekly.2008$Lag2)
train.Direction <- Direction[train]
set.seed(1)
knn.pred <- knn(train.X, test.X, train.Direction, k = 1)
table(knn.pred, Direction.2008)
mean(knn.pred == Direction.2008)
nb.fit <- naiveBayes(Direction ~ Lag2, data = weekly, subset = train)
nb.fit
nb.class <- predict(nb.fit, weekly.2008)
table(nb.class, Direction.2008)
mean(nb.class == Direction.2008)
results <- data.frame(algorithm = c("Logistic", "LDA", "QDA", "KNN", "Naive Bayes"),
accuracy = c(mean(test.pred == Direction.2008),
mean(lda.class == Direction.2008),
mean(qda.class == Direction.2008),
mean(knn.pred == Direction.2008),
mean(nb.class == Direction.2008)))
results
# Evaluate logistic regression using Lag 1 and Lag2
glm.j <- glm(
Direction ~ Lag1 + Lag2, data = weekly, family = binomial, subset = train)
test.probs.j <- predict(glm.train, weekly.2008, type = "response")
test.pred.j <- rep("Down", 104)
test.pred.j[test.probs.j > 0.5] <- "Up"
table(test.pred.j, Direction.2008)
mean(test.pred.j == Direction.2008)
# Evaluate logistic regression with the interaction between Lag1 and Lag2
glm.int.j<- glm(
Direction ~ Lag1 * Lag2 * Lag3, data = weekly, family = binomial, subset = train)
test.probs.int.j <- predict(glm.train, weekly.2008, type = "response")
test.pred.int.j <- rep("Down", 104)
test.pred.int.j[test.probs.j > 0.5] <- "Up"
table(test.pred.int.j, Direction.2008)
mean(test.pred.int.j == Direction.2008)
# Evaluate LDA and QDA using x^2 transformation
lda.fit.j <- lda(Direction ~ I(Lag2^2), data = weekly, subset = train)
lda.fit.j
lda.pred.j <- predict(lda.fit.j, weekly.2008)
lda.class.j <- lda.pred.j$class
table(lda.class.j, Direction.2008)
mean(lda.class.j == Direction.2008)
qda.fit.j <- qda(Direction ~ I(Lag2^2), data = weekly, subset = train)
qda.fit.j
qda.class.j <- predict(qda.fit.j, weekly.2008)$class
table(qda.class.j, Direction.2008)
mean(qda.class.j == Direction.2008)
# KNN using k = 5 and k = 10
set.seed(4)
knn.pred.j <- knn(train.X, test.X, train.Direction, k = 5)
table(knn.pred.j, Direction.2008)
mean(knn.pred.j == Direction.2008)
set.seed(5)
knn.pred.j2 <- knn(train.X, test.X, train.Direction, k = 10)
table(knn.pred.j2, Direction.2008)
mean(knn.pred.j2 == Direction.2008)
boston <- Boston
summary(boston)
cor_boston <- cor(boston)
View(cor_boston)
# Create qualitative variable that indicates if crim value is above or below median
crim_median <- median(boston$crim)
boston$mcrim <- apply(boston, 1, FUN = function(x) if(x[1] > crim_median) "above"
else "below")
boston$mcrim <- as.factor(boston$mcrim)
# Create training and test sets
smp_size <- floor(0.75 * nrow(boston))
set.seed(2)
train.ind <- sample(seq_len(nrow(boston)), replace = F, size = smp_size)
train.bos <- boston[train.ind, ]
test.bos <- boston[-train.ind, ]
mcrim.test <- as.factor(boston$mcrim[-train.ind])
# Logistic regression using rad, tax, lstat, indus, black, and medv
glm.boston <- glm(mcrim ~ rad + tax + lstat + indus + black + medv,
data = boston, family = binomial, subset = train.ind)
summary(glm.boston)
blog.probs <- predict(glm.boston, test.bos, type = "response")
contrasts(boston$mcrim)
blog.pred <- rep("below", length(test.bos))
blog.pred[blog.probs < 0.5] <- "above"
table(blog.pred, mcrim.test)
(53 + 6) / (53 + 8 + 7 + 6)
# Logistic regression using rad, lstat, indus, black, and medv
glm.boston2 <- glm(mcrim ~ rad + lstat + indus + black + medv,
data = boston, family = binomial, subset = train.ind)
summary(glm.boston2)
blog2.probs <- predict(glm.boston2, test.bos, type = "response")
blog2.pred <- rep("below", length(test.bos))
blog2.pred[blog.probs < 0.5] <- "above"
table(blog2.pred, mcrim.test)
# LDA using rad, lstat, indus, black, and medv
lda.boston <- lda(mcrim ~ rad + lstat + indus + black + medv,
data = boston, subset = train.ind)
lda_bos.pred <- predict(lda.boston, test.bos)
lda_bos.class <- lda_bos.pred$class
table(lda_bos.class, mcrim.test)
(46 + 55) / (46 + 55 + 22 + 4)
# LDA using just lstat and medv
lda.boston2 <- lda(mcrim ~ lstat + medv,
data = boston, subset = train.ind)
lda_bos2.pred <- predict(lda.boston2, test.bos)
lda_bos2.class <- lda_bos2.pred$class
table(lda_bos2.class, mcrim.test)
(39 + 46) / (39 + 46 + 29 + 13)
# Naive Bayes using rad, lstat, indus, black, and medv
nb_bos.fit <- naiveBayes(mcrim ~ rad + lstat + indus + black + medv,
data = boston, subset = train.ind)
nb_bos.class <- predict(nb_bos.fit, test.bos)
table(nb_bos.class, mcrim.test)
(42 + 56) / (42 + 56 + 26 + 3)
# Naive Bayes using just lstat and medv
nb_bos2.fit <- naiveBayes(mcrim ~ lstat + medv,
data = boston, subset = train.ind)
nb_bos2.class <- predict(nb_bos2.fit, test.bos)
table(nb_bos2.class, mcrim.test)
(41 + 48) / (41 + 48 + 27 + 11)
# KNN using rad, lstat, indus, black, and medv
bos.train <- cbind(boston$rad, boston$lstat, boston$indus, boston$black, boston$medv)[train.ind, ]
bos.test <- cbind(boston$rad, boston$lstat, boston$indus, boston$black, boston$medv)[-train.ind, ]
bos.mcrim <- boston$mcrim[train.ind]
set.seed(3)
knn_bos.pred <- knn(bos.train, bos.test, bos.mcrim, k = 1)
table(knn_bos.pred, mcrim.test)
(58 + 47) / (58 + 47 + 10 + 12)
# KNN using rad, lstat, black, and medv k = 3
set.seed(3)
knn_bos2.pred <- knn(bos.train, bos.test, bos.mcrim, k = 3)
table(knn_bos2.pred, mcrim.test)
(56 + 49) / (56 + 49 + 12 + 10)
# KNN using lstat and medv
bos2.train <- cbind(boston$lstat, boston$medv)[train.ind, ]
bos2.test <- cbind(boston$lstat, boston$medv)[-train.ind, ]
set.seed(3)
knn_bos3.pred <- knn(bos2.train, bos2.test, bos.mcrim, k = 3)
table(knn_bos3.pred, mcrim.test)
(45 + 40) / (45 + 40 + 23 + 19)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(MASS)
library(boot)
boston.data <- Boston
u_hat <- mean(boston.data$medv)
se_hat <- sd(boston.data$medv) / sqrt(nrow(boston.data$medv))
se_hat <- sd(boston.data$medv) / sqrt(nrow(boston.data))
se_hat
u_medv.fn <- function(data, variable, index) {
sum(data$variable[index]) / length(index)
}
u_medv.fn(boston.data, medv, 1:100)
u_medv.fn <- function(data, variable, index) {
mean(data$variable[index])
}
u_medv.fn(boston.data, medv, 1:100)
u_medv.fn <- function(data, variable, index) {
mean(data$variable[index])
}
x <- u_medv.fn(boston.data, medv, 1:100)
x <- u_medv.fn(boston.data, medv, 1:100)
boston$medv[1:100]
library(ISLR2)
library(MASS)
library(boot)
boston.data <- Boston
boston$medv[1:100]
boston.data$medv[1:100]
y <- boston.data$medv[1:100]
mean(y)
u_medv.fn <- function(data, variable, index) {
+  mean(data$variable[index])
}
x <- u_medv.fn(boston.data, medv, 1:100)
u_medv.fn <- function(data, variable, index) {
z <- data$variable[index]
class(z)
}
x <- u_medv.fn(boston.data, medv, 1:100)
u_medv.fn <- function(data, index) {
z <- data$medv[index]
class(z)
}
x <- u_medv.fn(boston.data, 1:100)
u_medv.fn <- function(data, index) {
z <- data$medv[index]
sum(z) / length(z)
}
x <- u_medv.fn(boston.data, 1:100)
u_medv.fn <- function(data, index) {
z <- data$medv[index]
sum(z) / length(z)
}
boot(boston.data, u_medv.fn, R = 1000)
u_hat <- mean(boston.data$medv)
u_hat
se_hat <- sd(boston.data$medv) / sqrt(nrow(boston.data))
se_hat
?boot.ci
u_medv.fn <- function(data, index) {
z <- data$medv[index]
sum(z) / length(z)
}
# Bootstrap calcuation for part b
boot.b <- boot(boston.data, u_medv.fn, R = 1000)
boot.b
u_medv.fn <- function(data, index) {
z <- data$medv[index]
sum(z) / length(z)
}
# Bootstrap calcuation for part b
set.seed(8)
boot.b <- boot(boston.data, u_medv.fn, R = 1000)
boot.b
u_medv.fn <- function(data, index) {
z <- data$medv[index]
sum(z) / length(z)
}
# Bootstrap calcuation for part b
set.seed(8)
boot.b <- boot(boston.data, u_medv.fn, R = 1000)
boot.b
boot.ci(boot.b, conf = 0.95, type="all")
boot.ci(boot.b, conf = 0.95, type=c("normal", "basic"))
boot.ci(boot.b, conf = 0.95, type="all")
22.53281 - 2*0.3990518
22.53281 + 2*0.3990518
boot.ci(boot.b, conf = 0.95, type="all")
t.test(boston.data$medv)
med_hat <- median(boston.data$medv)
med_hat
med_medv.fn <- function(data, index) {
median(data$medv[index])
}
boot.h <- boot(boston.data, med_medv.fn, 1000)
boot.h
med_medv.fn <- function(data, index) {
median(data$medv[index])
}
set.seed(10)
boot.h <- boot(boston.data, med_medv.fn, 1000)
boot.h
?quantile()
# Get tenth percentile of medv
u_10 <- quantile(boston.data$medv, probs = 0.1, na.rm = FALSE)
u_10
med_medv.fn <- function(data, index) {
median(data$medv[index])
}
set.seed(10)
boot.f <- boot(boston.data, med_medv.fn, 1000)
boot.f
ten_medv.fn <- function(data, index) {
quantile(data$medv, probs = 0.1, na.rm = FALSE)
}
set.seed(2)
boot.h <- boot(boston.data, ten_medv.fn, 1000)
boot.h
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(MASS)
library(boot)
default.data <- Default
set.seed(1)
train.default <- sample(nrow(default.data), nrow(default.data) / 2)
glm.default <- glm(default ~ income + balance, data = default.data,
subset = train.default, family = binomial)
summary(glm.default)
boot.fn <- function(data, index)
+ coef(glm(default ~ income + balance, data = data,
subset = index, family = binomial))
boot.fn(default.data, train.default)
set.seed(9)
boot(default.data, boot.fn, 1000)
boston.data <- Boston
u_hat <- mean(boston.data$medv)
u_hat
se_hat <- sd(boston.data$medv) / sqrt(nrow(boston.data))
se_hat
u_medv.fn <- function(data, index) {
z <- data$medv[index]
sum(z) / length(z)
}
# Bootstrap calcuation for part b
set.seed(8)
boot.b <- boot(boston.data, u_medv.fn, R = 1000)
boot.b
# Bootstrap from part c estimates mean = 22.53281 and std err = 0.3990518
low_ci <- 22.53281 - 2*0.3990518
upper_ci <- 22.53281 + 2*0.3990518
# Use boot.ci() function to estimate confidence intervals
boot.ci(boot.b, conf = 0.95, type="all")
# Use t-test to estimate confidence intervals
t.test(boston.data$medv)
med_hat <- median(boston.data$medv)
med_hat
med_medv.fn <- function(data, index) {
median(data$medv[index])
}
set.seed(10)
boot.f <- boot(boston.data, med_medv.fn, 1000)
boot.f
# Get tenth percentile of medv
u_10 <- quantile(boston.data$medv, probs = 0.1, na.rm = FALSE)
u_10
ten_medv.fn <- function(data, index) {
quantile(data$medv, probs = 0.1, na.rm = FALSE)
}
set.seed(2)
boot.h <- boot(boston.data, ten_medv.fn, 1000)
boot.h
boot.fn <- function(data, index)
coef(glm(default ~ income + balance, data = data,
subset = index, family = binomial))
boot.fn(default.data, train.default)
set.seed(9)
boot(default.data, boot.fn, 1000)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(MASS)
install.packages(leaps)
library(leaps)
install.packages("leaps")
?sample()
# Load Dataset
college.data <- College
# Create vector half the size of college.data that contains random set of indices
set.seed(1)
train <- sample(nrow(college.data), nrow(college.data) / 2)
# Initialize training and test data
college.train <- college.data[train, ]
college.test <- college.datta[-train, ]
# Load Dataset
college.data <- College
# Create vector half the size of college.data that contains random set of indices
set.seed(1)
train <- sample(nrow(college.data), nrow(college.data) / 2)
# Initialize training and test data
college.train <- college.data[train, ]
college.test <- college.data[-train, ]
View(college.data)
?lm()
# Load Dataset
college.data <- College
# Create vector half the size of college.data that contains random set of indices
set.seed(1)
train <- sample(nrow(college.data), 0.8 * nrow(college.data))
# Initialize training and test data
college.train <- college.data[train, ]
college.test <- college.data[-train, ]
?predict()
lm.college <- lm(Apps ~ ., data = college.data, subset = train)
summary(lm.college)
lm.predict <- predict(lm.college, college.test)
lm.college <- lm(Apps ~ ., data = college.data, subset = train)
summary(lm.college)
lm.predict <- predict(lm.college, college.test)
mean((college.test$Apps - lm.predict)^2)
View(college.test)
lm.college <- lm(Apps ~ ., data = college.data, subset = train)
summary(lm.college)
lm.predict <- predict(lm.college, college.test)
lm.mse <- mean((college.test$Apps - lm.predict)^2)
lm.mse
install.packages("glmnet")
library(ISLR2)
library(MASS)
library(leaps)
library(glmnet)
