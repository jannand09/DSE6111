# PCR
set.seed(11)
pcr.boston <- pcr(crim ~ ., data = boston.data, scale = T,
validation = "CV")
validationplot(pcr.boston, val.type = "MSEP")
# Fit PCR to entire data set using M = 8
pcr.boston <- pcr(y2 ~ x2, scale = T, ncomp = 5)
summary(pcr.boston)
# Use Validation-Set Approach to Determine Best Subset Selection Model
regfit.best <- regsubsets(crim ~ ., data = boston.data[train, ], nvmax = 13)
# Create test matrix
test.mat <- model.matrix(crim ~ ., data = boston.data[test, ])
# Compute test MSE for all possible amounts of variables used in the model
val.errors <- rep(NA, 13)
for (i in 1:13) {
coefi <- coef(regfit.best, id = i)
pred <- test.mat[, names(coefi)] %*% coefi
val.errors[i] <- mean((boston.data$crim[test] - pred)^2)
}
# Get coefficient estimates for model with best subset of variables
best.subset <- which.min(val.errors)
coef(regfit.best, best.subset)
# Predict the number of applications using the PCR model
pcr.pred <- predict(pcr.fit, x[-train, ], ncomp = 17)
pcr.mse <- mean((pcr.pred - y[-train])^2)
pcr.mse
mse.models <- data.frame(
model = c("least.squares", "ridge.regression", "lasso", "pcr", "pls"),
mse = c(lm.mse, ridge.mse, lasso.mse, pcr.mse, pls.mse),
stringsAsFactors = F
)
mse.models
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(MASS)
library(tree)
# Split data into training and test data
set.seed(1)
train <- sample(1:nrow(Carseats), nrow(Carseats) / 2)
sales.test <- Carseats[-train, "Sales"]
tree.sales <- tree(Sales ~ ., data = Carseats, subset = train)
summary(tree.sales)
plot(tree.sales)
text(tree.sales, pretty = 0)
sales.pred <- predict(tree.sales, newdata = Carseats[-train, ])
plot(sales.pred, sales.test)
abline(0, 1)
mean((sales.pred - sales.test)^2)
cv.sales <- cv.tree(tree.sales)
plot(cv.sales$size, cv.sales$dev, type = "b")
prune.sales <- prune.tree(tree.sales, best = 14)
plot(prune.sales)
text(prune.sales, pretty = 0)
prune.pred <- predict(prune.sales, newdata = Carseats[-train, ])
plot(prune.pred, sales.test)
mean((prune.pred - sales.test)^2)
library(randomForest)
set.seed(2)
bag.sales <- randomForest(Sales ~ ., data = Carseats, subset = train,
mtry = (ncol(Carseats) - 1), importance = T)
bag.sales
bag.pred <- predict(bag.sales, newdata = Carseats[-train, ])
plot(bag.pred, sales.test)
abline(0, 1)
mean((bag.pred - sales.test)^2)
set.seed(2)
# Create random forest model using default m = p/3
rf.sales <- randomForest(Sales ~ ., data = Carseats, subset = train,
importance = T)
rf.pred <- predict(rf.sales, newdata = Carseats[-train, ])
mean((rf.pred - sales.test)^2)
set.seed(2)
# Create random forest model using default m = 6
rf.sales6 <- randomForest(Sales ~ ., data = Carseats, subset = train,
mtry = 6, importance = T)
rf.pred6 <- predict(rf.sales6, newdata = Carseats[-train, ])
mean((rf.pred6 - sales.test)^2)
set.seed(2)
# Create random forest model using default m = 9
rf.sales9 <- randomForest(Sales ~ ., data = Carseats, subset = train,
mtry = 9, importance = T)
rf.pred9 <- predict(rf.sales9, newdata = Carseats[-train, ])
mean((rf.pred9 - sales.test)^2)
importance(rf.sales6)
varImpPlot(rf.sales6)
# Analyze data using BART
library(BART)
x <- Carseats[, 2:11]
y <- Carseats[, "Sales"]
xtrain <- x[train, ]
ytrain <- y[train]
xtest <- x[-train, ]
ytest <- y[-train]
# Run BART with default settings
set.seed(1)
bartfit <- gbart(xtrain, ytrain, x.test = xtest)
bart.pred <- bartfit$yhat.test.mean
mean((ytest - bart.pred)^2)
# Divide OJ data set into training and test data
set.seed(3)
train.oj <- sample(1:nrow(OJ), 800)
test.oj <- OJ[-train.oj, ]
# Fit a classification tree to OJ data with Purchase as the response
tree.oj <- tree(Purchase ~ ., data = OJ, subset = train.oj)
summary(tree.oj)
tree.oj
plot(tree.oj)
text(tree.oj, pretty = 0)
# Use classification tree to predict responses of test data
oj.pred <- predict(tree.oj, test.oj, type = "class")
# Generate confusion matrix
table(oj.pred, test.oj$Purchase)
(15 + 31) / (148 + 31 + 15 + 76)
# Use cross-validation to determine if pruning the tree may result in better prediction error
set.seed(4)
cv.oj <- cv.tree(tree.oj, FUN = prune.misclass)
names(cv.oj)
cv.oj
# Create plot of cross-validated training error over tree size
plot(cv.oj$size, cv.oj$dev, type = "b")
prune.oj <- prune.misclass(tree.oj, best = 5)
plot(prune.oj)
text(prune.oj, pretty = 0)
summary(prune.oj)
# Predict response with pruned tree
prune.oj.pred <- predict(prune.oj, test.oj, type = "class")
# Generate confusion matrix for pruned tree
table(prune.oj.pred, test.oj$Purchase)
(15 + 31) / (148 + 31 + 15 + 76)
?na.omit
hitters.data <- na.omit(Hitters)
View(hitters.data)
hitters.train <- c(1:200)
hitters.data <- na.omit(Hitters)
hitters.data$Salary <- log(hitters.data$Salary)
View(hitters.data)
hitters.train <- c(1:200)
hitters.test <- c(201:nrow(hitters.data))
install.packages("gbm")
library(gbm)
set.seed(5)
boost.hitters <- gbm(Salary ~ ., data = hitters.data[hitters.train, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4)
View(boost.hitters)
?rep
?gbm
library(gbm)
set.seed(5)
tunings <- c(0.001, 0.01, 0.2, 0.5, 1.0)
gbm.training <- data.frame(lambda = tunings,
training.error = rep(NA, 5))
for (x in length(tunings)) {
boost.hitters <- gbm(Salary ~ ., data = hitters.data[hitters.train, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
gbm.training[x, "training.error"] <-  mean(boost.hitters$train.error)
}
gbm.training
library(gbm)
set.seed(5)
tunings <- c(0.001, 0.01, 0.2, 0.5, 1.0)
gbm.training <- data.frame(lambda = tunings,
training.error = rep(NA, 5))
for (x in 1:length(tunings)) {
boost.hitters <- gbm(Salary ~ ., data = hitters.data[hitters.train, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
gbm.training[x, "training.error"] <-  mean(boost.hitters$train.error)
}
gbm.training
library(gbm)
set.seed(5)
tunings <- c(0.001, 0.01, 0.2, 0.5, 0.75, 1.0)
gbm.training <- data.frame(lambda = tunings,
training.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
boost.hitters <- gbm(Salary ~ ., data = hitters.data[hitters.train, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
gbm.training[x, "training.error"] <-  mean(boost.hitters$train.error)
}
gbm.training
plot(gbm.training$lambda, gbm.training$training.error)
plot(gbm.training$lambda, gbm.training$training.error, type = "b")
gbm.test <- data.frame(lambda = tunings,
test.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
boost.hitters <- gbm(Salary ~ ., data = hitters.data[hitters.train, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.hitters, newdata = hitters.data[hitters.test, ],
n.trees = 1000)
gbm.test[x, "test.error"] <-  mean((yhat.boost - hitters.data$Salary[hitters.test])^2)
}
gbm.test
plot(gbm.test$lambda, gbm.test$test.error, type = "b")
# Create LS regression with Salary as the predictor and determine test MSE
lm.hitters <- lm(Salary ~ ., data = hitters.data, subset = hitters.train)
lm.predict <- predict(lm.hitters, newdata = hitters.data[hitters.test, ])
lm.mse <- mean((lm.predict - hitters.data$Salary[hitters.test])^2)
lm.mse
?seq
x <- model.matrix(Salary ~ ., hitters.data)[-1]
y <- hitters.data$Salary
lambda.grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x[hitters.train, ], y[hitters.train], alpha = 1,
lambda = lambda.grid)
library(glmnet)
x <- model.matrix(Salary ~ ., hitters.data)[-1]
y <- hitters.data$Salary
lambda.grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x[hitters.train, ], y[hitters.train], alpha = 1,
lambda = lambda.grid)
?College
dim(x[hitters.train, ])
library(glmnet)
x <- model.matrix(Salary ~ ., hitters.data)[, -1]
y <- hitters.data$Salary
lambda.grid <- 10^seq(10, -2, length = 100)
lasso.mod <- glmnet(x[hitters.train, ], y[hitters.train], alpha = 1,
lambda = lambda.grid)
set.seed(7)
cv.out <- cv.glmnet(x[hitters.train, ], y[hitters.train], alpha = 1)
bestlam <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s = bestlam, newx = x[hitters.test, ])
lasso.mse <- mean((lasso.pred - y[hitters.test])^2)
lasso.mse
# Create boosting model using shrinkage, or tuning parameter, equal to 0.01
boost.hitters <- gbm(Salary ~ ., data = hitters.data[hitters.train, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = 0.01)
summary(boost.hitters)
?Hitters
gbm.test <- data.frame(lambda = tunings,
test.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
set.seed(5)
boost.hitters <- gbm(Salary ~ ., data = hitters.data[hitters.train, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.hitters, newdata = hitters.data[hitters.test, ],
n.trees = 1000)
gbm.test[x, "test.error"] <-  mean((yhat.boost - hitters.data$Salary[hitters.test])^2)
}
gbm.test
plot(gbm.test$lambda, gbm.test$test.error, type = "b")
set.seed(5)
bag.hitters <- randomForest(Salary ~ ., data = hitters.data,
subset = hitters.train, mtry = 19,
importance = T)
yhat.bag <- predict(bag.hitters, newdata = hitters.data[hitters.test, ])
mean((yhat.bag - hitters.data$Salary[hitters.test])^2)
# Load libraries
library(ISLR2)
library(MASS)
library(leaps)
library(glmnet)
library(pls)
library(boot)
library(tree)
library(BART)
# Import wine quality data
white.quality <- read.csv("winequality-white.csv", sep=";", na.strings = "?", stringsAsFactors = T)
setwd("C:/Users/janna/Documents/Merrimack MSDS/DSE6111/Final Project")
# Load libraries
library(ISLR2)
library(MASS)
library(leaps)
library(glmnet)
library(pls)
library(boot)
library(tree)
library(BART)
# Import wine quality data
white.quality <- read.csv("winequality-white.csv", sep=";", na.strings = "?", stringsAsFactors = T)
View(white.quality)
red.quality <- read.csv("winequality-red.csv", sep=";", na.strings = "?", stringsAsFactors = T)
View(red.quality)
# Check correlations between predictors and the number of drinks
white_cor <- cor(white.quality, use="complete.obs")
print(white_cor[12, ])
# Multiple linear regression with all predictors
lm.white <- lm(quality ~ ., data = white.quality)
summary(lm.white)
# Create training data
set.seed(10)
train.white <- sample(1:nrow(white.quality), 0.5 * nrow(white.quality))
test.white <- (-train.white)
# Train the multiple linear regression model with selected predictors
lm.train <- lm(quality ~ volatile.acidity + residual.sugar + free.sulfur.dioxide
+ density + pH + sulphates + alcohol, data = white.quality,
subset = train.white)
summary(lm.train)
?abline
?resid
plot(lm.train$fitted.values, resid(lm.train))
abline(0)
res <- resid(lm.train)
plot(fitted(lm.train), res)
abline(0,0)
?leaps
# Create regression tree model for quality as response
tree.white <- tree(quality ~ ., data = white.quality, subset = train.white)
summary(tree.white)
# Plot the regression tree
plot(tree.white)
text(tree.white, pretty = 0)
tree.pred <- predict(tree.white, newdate = white.quality[-train.white, ])
tree.mse <- mean((tree.pred - y.test)^2)
y.test <- y[test.white]
# Create matrix of x, the predictors, and vector of y, the response
x <- model.matrix(quality ~ ., white.quality)[, -1]
y <- white.quality$quality
y.test <- y[test.white]
# Create regression tree model for quality as response
tree.white <- tree(quality ~ ., data = white.quality, subset = train.white)
summary(tree.white)
# Plot the regression tree
plot(tree.white)
text(tree.white, pretty = 0)
tree.pred <- predict(tree.white, newdate = white.quality[-train.white, ])
tree.mse <- mean((tree.pred - y.test)^2)
tree.cv <- cv.tree(tree.white)
plot(tree.cv$size, tree.cv$dev, type = "b")
which.min(tree.cv$dev)
tree.cv
tree.mse
prune.mse
prune.wine <- prune.tree(tree.wine, best = 6)
# Create regression tree model for quality as response
tree.wine <- tree(quality ~ ., data = wine.data, subset = train.wine)
wine.data <- read.csv("winequality-wine.csv", sep=";", na.strings = "?", stringsAsFactors = T)
setwd("C:/Users/janna/Documents/Merrimack MSDS/DSE6111/Final Project")
wine.data <- read.csv("winequality-wine.csv", sep=";", na.strings = "?", stringsAsFactors = T)
# Import wine quality data
wine.data <- read.csv("winequality-white.csv", sep=";", na.strings = "?", stringsAsFactors = T)
View(wine.data)
# Check correlations between predictors and the number of drinks
wine_cor <- cor(wine.data, use="complete.obs")
print(wine_cor[12, ])
# Multiple linear regression with all predictors
lm.wine <- lm(quality ~ ., data = wine.data)
summary(lm.wine)
# Create training data
set.seed(10)
train.wine <- sample(1:nrow(wine.data), 0.5 * nrow(wine.data))
test.wine <- (-train.wine)
# Create regression tree model for quality as response
tree.wine <- tree(quality ~ ., data = wine.data, subset = train.wine)
summary(tree.wine)
# Plot the regression tree
plot(tree.wine)
text(tree.wine, pretty = 0)
tree.pred <- predict(tree.wine, newdate = wine.data[test.wine, ])
tree.mse <- mean((tree.pred - y.test)^2)
tree.mse
# Attempt to prune the tree and get better test results
tree.cv <- cv.tree(tree.wine)
plot(tree.cv$size, tree.cv$dev, type = "b")
prune.wine <- prune.tree(tree.wine, best = 6)
prune.pred <- predict(prune.wine, newdata = wine.data[test.wine, ])
prune.mse <- ((prune.pred - y.test)^2)
prune.mse
prune.mse <- mean((prune.pred - y.test)^2)
prune.mse
# Create bagging model to predict wine quality
set.seed(90)
bag.wine <- randomForest(quality ~ ., data = wine.data, subset = train.wine,
mtry = (ncol(wine.data) - 1), importance = T)
library(ISLR2)
library(MASS)
library(leaps)
library(glmnet)
library(pls)
library(boot)
library(tree)
library(randomForest)
library(gbm)
library(BART)
# Create bagging model to predict wine quality
set.seed(90)
bag.wine <- randomForest(quality ~ ., data = wine.data, subset = train.wine,
mtry = (ncol(wine.data) - 1), importance = T)
bag.wine
bag.pred <- predict(bag.wine, newdata = wine.data[test.wine, ])
mean((bag.pred - y.test)^2)
set.seed(90)
rf.wine <- randomForest(quality ~ ., data = wine.data[train.wine, ])
rf.pred <- predict(rf.wine, newdata = wine.data[test.wine, ])
rf.mse <- mean((rf.pred - y.test)^2)
rf.mse
tunings <- c(0.001, 0.01, 0.2, 0.5, 1.0)
boost.errors <- data.frame(lambda = tunings,
training.error = rep(NA, length(tunings)),
test.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
boost.errors[x, "training.error"] <- mean(boost.wine$train.error)
}
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.wine, newdata = wine.data[test.wine, ],
n.trees = 1000)
boost.errors[x, "test.error"] <- mean((yhat.boost - y.test)^2)
}
boost.errors
tunings <- c(0.001, 0.005, 0.01, 0.015, 0.020)
boost.errors <- data.frame(lambda = tunings,
training.error = rep(NA, length(tunings)),
test.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
boost.errors[x, "training.error"] <- mean(boost.wine$train.error)
}
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.wine, newdata = wine.data[test.wine, ],
n.trees = 1000)
boost.errors[x, "test.error"] <- mean((yhat.boost - y.test)^2)
}
boost.errors
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(MASS)
library(leaps)
library(glmnet)
library(pls)
library(boot)
library(tree)
library(randomForest)
library(gbm)
library(BART)
# Import wine quality data
wine.data <- read.csv("winequality-white.csv", sep=";", na.strings = "?", stringsAsFactors = T)
View(wine.data)
white_cor <- cor(white.quality, use="complete.obs")
white_cor <- cor(wine.data, use="complete.obs")
print(white_cor[12, ])
lm.wine <- lm(quality ~ ., data = wine.data)
summary(lm.wine)
# Create training and test data
set.seed(10)
train.wine <- sample(1:nrow(wine.data), 0.5 * nrow(wine.data))
test.wine <- (-train.wine)
# Train a linear model with statistically significant predictors
lm.train <- lm(quality ~ volatile.acidity + residual.sugar + free.sulfur.dioxide
+ density + pH + sulphates + alcohol, data = wine.data,
subset = train.wine)
summary(lm.train)
# Use trained linear model to predict the wine quality
lm.predict <- predict(lm.train, wine.data[test.wine, ])
lm.mse <- mean((lm.predict - wine.data[test.wine, ]$quality)^2)
lm.mse
# Use first linear model to predict the wine quality
first.lm.predict <- predict(lm.wine, wine.data[test.wine, ])
first.lm.mse <- mean((first.lm.predict - wine.data$quality[test.wine])^2)
first.lm.mse
# Use trained linear model to predict the wine quality
lm.predict <- predict(lm.train, wine.data[test.wine, ])
lm.mse <- mean((lm.predict - wine.data$quality[test.wine])^2)
lm.mse
# Train the first linear model
first.lm.wine <- lm(quality ~ ., data = wine.data, subset = train.wine)
summary(first.lm.wine)
# Use first linear model to predict the wine quality
first.lm.predict <- predict(first.lm.wine, wine.data[test.wine, ])
first.lm.mse <- mean((first.lm.predict - wine.data$quality[test.wine])^2)
first.lm.mse
# Create matrix of x, the predictors, and vector of y, the response
x <- model.matrix(quality ~ ., wine.data)[, -1]
y <- wine.data$quality
y.test <- y[test.wine]
# Create a lambda grid and use it to form ridge regression model
lambda.grid <- 10^seq(10, -2, length = 100)
ridge.mod <- glmnet(x[train.wine, ], y[train.wine], alpha = 0, lambda = lambda.grid,
thresh = 1e-12)
summary(ridge.mod)
# Determine the best lambda, or tuning parameter, using cross-validation
set.seed(2)
cv.out <- cv.glmnet(x[train.wine, ], y[train.wine], alpha = 0)
plot(cv.out)
bestlam.ridge <- cv.out$lambda.min
bestlam.ridge
# Predict the response of test data using ridge regression with best tuning parameter
ridge.pred <- predict(ridge.mod, s = bestlam.ridge, newx = x[test.wine, ])
ridge.mse <- mean((ridge.pred - y.test)^2)
ridge.mse
lasso.mod <- glmnet(x[train.wine, ], y[train.wine], alpha = 1, lambda = lambda.grid)
plot(lasso.mod)
# Perform cross-validation to determine best tuning parameter
set.seed(2)
cv.out <- cv.glmnet(x[train.wine, ], y[train.wine], alpha = 1)
plot(cv.out)
bestlam.lasso <- cv.out$lambda.min
bestlam.lasso
# Predict the response of test data and calculate MSE
lasso.pred <- predict(lasso.mod, s = bestlam.lasso, newx = x[test.wine, ])
lasso.mse <- mean((lasso.pred - y.test)^2)
lasso.mse
