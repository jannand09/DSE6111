for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.wine, newdata = wine.data[test.wine, ],
n.trees = 1000)
boost.errors[x, "test.error"] <- mean((yhat.boost - y.test)^2)
}
boost.errors
tree.cv <- cv.tree(tree.wine)
plot(tree.cv$size, tree.cv$dev, type = "b")
# Plot the pruned regression tree
plot(prune.wine)
text(prune.wine, pretty = 0)
prune.wine <- prune.tree(tree.wine, best = 6)
# Plot the pruned regression tree
plot(prune.wine)
text(prune.wine, pretty = 0)
varImpPlot(rf.wine)
importance(rf,wine)
set.seed(90)
rf.wine <- randomForest(quality ~ ., data = wine.data[train.wine, ],
importance = T)
importance(rf,wine)
importance(rf.wine)
varImpPlot(rf.wine)
knitr::opts_chunk$set(echo = TRUE)
model.errors <- data.frame(model = c("Least Squares", "Ridge Regression", "The LASSO", "PLS",
"Best Subset", "Forward Stepwise", "Backward Stepwise", "Tree",
"Pruned Tree", "Bagging", "RF", "Boosting"),
test.error = rep(NA, 12))
View(model.errors)
knitr::opts_chunk$set(echo = TRUE)
library(ISLR2)
library(MASS)
library(leaps)
library(glmnet)
library(pls)
library(boot)
library(tree)
library(randomForest)
library(gbm)
library(BART)
# Import wine quality data
wine.data <- read.csv("winequality-white.csv", sep=";", na.strings = "?", stringsAsFactors = T)
View(wine.data)
white_cor <- cor(wine.data, use="complete.obs")
print(white_cor[12, ])
model.errors <- data.frame(model = c("Least Squares", "Ridge Regression", "The LASSO", "PLS",
"Best Subset", "Forward Stepwise", "Backward Stepwise", "Tree",
"Pruned Tree", "Bagging", "RF", "Boosting"),
test.error = rep(NA, 12))
lm.wine <- lm(quality ~ ., data = wine.data)
summary(lm.wine)
# Create training and test data
set.seed(10)
train.wine <- sample(1:nrow(wine.data), 0.5 * nrow(wine.data))
test.wine <- (-train.wine)
# Train a linear model with statistically significant predictors
lm.train <- lm(quality ~ volatile.acidity + residual.sugar + free.sulfur.dioxide
+ density + pH + sulphates + alcohol, data = wine.data,
subset = train.wine)
summary(lm.train)
# Use trained linear model to predict the wine quality
lm.predict <- predict(lm.train, wine.data[test.wine, ])
lm.mse <- mean((lm.predict - wine.data$quality[test.wine])^2)
lm.mse
model.errors[model.errors$model == "Least Squares", "test.error"] <- lm.mse
# Train the first linear model
first.lm.wine <- lm(quality ~ ., data = wine.data, subset = train.wine)
summary(first.lm.wine)
# Use first linear model to predict the wine quality
first.lm.predict <- predict(first.lm.wine, wine.data[test.wine, ])
first.lm.mse <- mean((first.lm.predict - wine.data$quality[test.wine])^2)
first.lm.mse
# Create matrix of x, the predictors, and vector of y, the response
x <- model.matrix(quality ~ ., wine.data)[, -1]
y <- wine.data$quality
y.test <- y[test.wine]
# Create a lambda grid and use it to form ridge regression model
lambda.grid <- 10^seq(10, -2, length = 100)
ridge.mod <- glmnet(x[train.wine, ], y[train.wine], alpha = 0, lambda = lambda.grid,
thresh = 1e-12)
summaryridge.mod
# Create a lambda grid and use it to form ridge regression model
lambda.grid <- 10^seq(10, -2, length = 100)
ridge.mod <- glmnet(x[train.wine, ], y[train.wine], alpha = 0, lambda = lambda.grid,
thresh = 1e-12)
summary(ridge.mod)
# Determine the best lambda, or tuning parameter, using cross-validation
set.seed(2)
cv.out <- cv.glmnet(x[train.wine, ], y[train.wine], alpha = 0)
plot(cv.out)
bestlam.ridge <- cv.out$lambda.min
bestlam.ridge
# Predict the response of test data using ridge regression with best tuning parameter
ridge.pred <- predict(ridge.mod, s = bestlam.ridge, newx = x[test.wine, ])
ridge.mse <- mean((ridge.pred - y.test)^2)
ridge.mse
model.errors[model.errors$model == "Ridge Regression", "test.error"] <- ridge.mse
lasso.mod <- glmnet(x[train.wine, ], y[train.wine], alpha = 1, lambda = lambda.grid)
plot(lasso.mod)
# Perform cross-validation to determine best tuning parameter
set.seed(2)
cv.out <- cv.glmnet(x[train.wine, ], y[train.wine], alpha = 1)
plot(cv.out)
bestlam.lasso <- cv.out$lambda.min
bestlam.lasso
# Predict the response of test data and calculate MSE
lasso.pred <- predict(lasso.mod, s = bestlam.lasso, newx = x[test.wine, ])
lasso.mse <- mean((lasso.pred - y.test)^2)
lasso.mse
model.errors[model.errors$model == "The LASSO", "test.error"] <- lasso.mse
lasso.coef <- predict(lasso.mod, type = "coefficients", s = bestlam.lasso)[1:11, ]
lasso.coef
lasso.coef[lasso.coef != 0]
# Create PLS model on the wine wine quality data
set.seed(2)
pls.fit <- plsr(quality ~ ., data = wine.data, subset = train.wine, scale = T,
validation = "CV")
summary(pls.fit)
# Plot MSEP over the number of components
validationplot(pls.fit, val.type = "MSEP")
axis(side=1, at=seq(1, 20, by=1))
# Predict quality of the wine using PLS
pls.pred <- predict(pls.fit, newdata = x[test.wine, ], ncomp=3)
pls.mse <- mean((pls.pred - y.test)^2)
pls.mse
model.errors[model.errors$model == "PLS", "test.error"] <- pls.mse
# Function to predict response using best subset selection
predict.regsubsets <- function(object, newdata, id, ...) {
form <- as.formula(object$call[[2]])
mat <- model.matrix(form, newdata)
coefi <- coef(object, id = id)
xvars <- names(coefi)
mat[, xvars] %*% coefi
}
# Use validation set approach to determine best subset selection model
regfit.best <- regsubsets(quality ~ ., data = wine.data[train.wine, ], nvmax = 11)
# Create test matrix
test.mat <- model.matrix(quality ~ ., data = wine.data[test.wine, ])
# Compute test MSE for all possible amounts of variables used in the model
val.errors <- rep(NA, 13)
for (i in 1:11) {
coefi <- coef(regfit.best, id = i)
pred <- test.mat[, names(coefi)] %*% coefi
val.errors[i] <- mean((wine.data$quality[test.wine] - pred)^2)
}
# Get coefficient estimates for model with best subset collection
best.subset <- which.min(val.errors)
val.errors[best.subset]
coef(regfit.best, best.subset)
# Best subset selection using cross-validation method
k <- 10
n <- nrow(wine.data)
set.seed(11)
folds <- sample(rep(1:k, length = n))
cv_sub.errors <- matrix(NA, k, 11,
dimnames = list(NULL, paste(1:11)))
for (j in 1:k) {
cv_sub.fit <- regsubsets(quality ~ .,
data = wine.data[folds != j, ],
nvmax = 11)
for (i in 1:11) {
pred.cv_sub <- predict.regsubsets(cv_sub.fit, wine.data[folds == j, ], id = i)
cv_sub.errors[j, i] <- mean((wine.data$quality[folds == j] - pred.cv_sub)^2)
}
}
cv_sub.cv.errors <- apply(cv_sub.errors, 2, mean)
par(mfrow = c(1,1))
plot(cv_sub.cv.errors, type = "b")
which.min(cv_sub.cv.errors)
cv_sub.mse <- cv_sub.cv.errors[["8"]]
cv_sub.mse
model.errors[model.errors$model == "Best Subset", "test.error"] <- cv_sub.mse
k <- 10
n <- nrow(wine.data)
set.seed(11)
folds <- sample(rep(1:k, length = n))
f.cv.errors <- matrix(NA, k, 11,
dimnames = list(NULL, paste(1:11)))
for (j in 1:k) {
fstep.fit <- regsubsets(quality ~ .,
data = wine.data[folds != j, ],
nvmax = 11,
method = "forward")
for (i in 1:11) {
pred.forward <- predict.regsubsets(fstep.fit, wine.data[folds == j, ], id = i)
f.cv.errors[j, i] <- mean((wine.data$quality[folds == j] - pred.forward)^2)
}
}
forward.cv.errors <- apply(f.cv.errors, 2, mean)
forward.cv.errors
par(mfrow = c(1,1))
plot(forward.cv.errors, type = "b")
which.min(forward.cv.errors)
forward.mse <- forward.cv.errors[["8"]]
forward.mse
model.errors[model.errors$model == "Forward Stepwise", "test.error"] <- forward.mse
# Backward Step-wise Subset Selection Using Cross Validation
k <- 10
n <- nrow(wine.data)
set.seed(11)
folds <- sample(rep(1:k, length = n))
b.cv.errors <- matrix(NA, k, 11,
dimnames = list(NULL, paste(1:11)))
for (j in 1:k) {
bstep.fit <- regsubsets(quality ~ .,
data = wine.data[folds != j, ],
nvmax = 11,
method = "backward")
for (i in 1:11) {
pred.backward <- predict.regsubsets(fstep.fit, wine.data[folds == j, ], id = i)
b.cv.errors[j, i] <-
mean((wine.data$quality[folds == j] - pred.backward)^2)
}
}
backward.cv.errors <- apply(b.cv.errors, 2, mean)
backward.cv.errors
par(mfrow = c(1,1))
plot(backward.cv.errors, type = "b")
which.min(backward.cv.errors)
backward.mse <- backward.cv.errors[["11"]]
backward.mse
model.errors[model.errors$model == "Backward Stepwise", "test.error"] <- backward.mse
# Create regression tree model for quality as response
tree.wine <- tree(quality ~ ., data = wine.data, subset = train.wine)
summary(tree.wine)
# Plot the regression tree
plot(tree.wine)
text(tree.wine, pretty = 0)
tree.pred <- predict(tree.wine, newdate = wine.data[test.wine, ])
tree.mse <- mean((tree.pred - y.test)^2)
tree.mse
model.errors[model.errors$model == "Tree", "test.error"] <- tree.mse
# Use cross-validation to determine best tree size for pruning
tree.cv <- cv.tree(tree.wine)
plot(tree.cv$size, tree.cv$dev, type = "b")
# Prune tree and plot the tree
prune.wine <- prune.tree(tree.wine, best = 6)
plot(prune.wine)
text(prune.wine, pretty = 0)
# Predict response with pruned tree
prune.pred <- predict(prune.wine, newdata = wine.data[test.wine, ])
prune.mse <- mean((prune.pred - y.test)^2)
prune.mse
model.errors[model.errors$model == "Pruned Tree", "test.error"] <- prune.mse
set.seed(90)
bag.wine <- randomForest(quality ~ ., data = wine.data, subset = train.wine,
mtry = (ncol(wine.data) - 1), importance = T)
bag.wine
bag.pred <- predict(bag.wine, newdata = wine.data[test.wine, ])
bag.mse <- mean((bag.pred - y.test)^2)
bag.mse
model.errors[model.errors$model == "Bagging", "test.error"] <- bag.mse
set.seed(90)
rf.wine <- randomForest(quality ~ ., data = wine.data[train.wine, ],
importance = T)
rf.wine
importance(rf.wine)
varImpPlot(rf.wine)
rf.pred <- predict(rf.wine, newdata = wine.data[test.wine, ])
rf.mse <- mean((rf.pred - y.test)^2)
rf.mse
model.errors[model.errors$model == "RF", "test.error"] <- rf.mse
tunings <- c(0.001, 0.005, 0.01, 0.015, 0.020)
boost.errors <- data.frame(lambda = tunings,
training.error = rep(NA, length(tunings)),
test.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
boost.errors[x, "training.error"] <- mean(boost.wine$train.error)
}
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.wine, newdata = wine.data[test.wine, ],
n.trees = 1000)
boost.errors[x, "test.error"] <- mean((yhat.boost - y.test)^2)
}
boost.errors
tunings <- c(0.001, 0.005, 0.01, 0.02, 0.03)
boost.errors <- data.frame(lambda = tunings,
training.error = rep(NA, length(tunings)),
test.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
boost.errors[x, "training.error"] <- mean(boost.wine$train.error)
}
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.wine, newdata = wine.data[test.wine, ],
n.trees = 1000)
boost.errors[x, "test.error"] <- mean((yhat.boost - y.test)^2)
}
boost.errors
tunings <- c(0.001, 0.005, 0.01, 0.02, 0.03)
boost.errors <- data.frame(shrinkage = tunings,
training.error = rep(NA, length(tunings)),
test.error = rep(NA, length(tunings)))
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
boost.errors[x, "training.error"] <- mean(boost.wine$train.error)
}
for (x in 1:length(tunings)) {
set.seed(91)
boost.wine <- gbm(quality ~ ., data = wine.data[train.wine, ],
distribution = "gaussian", n.trees = 1000,
interaction.depth = 4, shrinkage = tunings[x])
yhat.boost <- predict(boost.wine, newdata = wine.data[test.wine, ],
n.trees = 1000)
boost.errors[x, "test.error"] <- mean((yhat.boost - y.test)^2)
}
boost.errors
tree.pred <- predict(tree.wine, newdata = wine.data[test.wine, ])
tree.mse <- mean((tree.pred - y.test)^2)
tree.mse
model.errors[model.errors$model == "Tree", "test.error"] <- tree.mse
model.errors[model.errors$model == "Boosting", "test.error"] <- min(boost.errors$test.error)
model.errors
sqrt(min(model.errors$test.error))
knitr::opts_chunk$set(echo = TRUE)
forest.data <- read.csv("forestfires.csv", sep=";", stringsAsFactors = T, na.strings = "?")
View(forest.data)
forest.data <- read.csv("forestfires.csv", sep=",", stringsAsFactors = T, na.strings = "?")
View(forest.data)
cor(forest.data[, -c(3,4)])
forset_cor <- cor(forest.data[, -c(3,4)])
forest_cor
forest_cor <- cor(forest.data[, -c(3,4)])
forest_cor
library(ISLR2)
library(MASS)
library(pls)
set.seed(2)
train <- sample(1:nrow(forest.data), nrow(forest.data) / 2)
test <- (-train)
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = forest.data, subset = train, scale = T,
validation = "CV")
forest.data <- read.csv("forestfires.csv", sep=",", stringsAsFactors = T)
forest.data <- na.omit(forest.data)
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = forest.data, subset = train, scale = T,
validation = "CV")
forest.data <- read.csv("forestfires.csv", sep=",", stringsAsFactors = T)
forest.data <- na.omit(forest.data[, -12])
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = forest.data, subset = train, scale = T,
validation = "CV")
View(forest.data)
forest.data <- read.csv("forestfires.csv", sep=",", stringsAsFactors = T)
forest.data <- na.omit(forest.data)
View(forest.data)
forest.data <- read.csv("forestfires.csv", sep=",", stringsAsFactors = T)
View(forest.data)
forest.data <- read.csv("forestfires.csv", sep=",", stringsAsFactors = T)
forest.data$area <- log(forest.data$area) + 1
forest.data <- read.csv("forestfires.csv", sep=",", stringsAsFactors = T)
forest.data$area <- log(1 + forest.data$area)
forest_cor <- cor(forest.data[, -c(3,4)])
forest_cor
set.seed(2)
train <- sample(1:nrow(forest.data), nrow(forest.data) / 2)
test <- (-train)
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = forest.data, subset = train, scale = T,
validation = "CV")
bike.data <- read.csv("SeoulBikeData.csv", sep=";", stringsAsFactors = T)
bike.data <- read.csv("SeoulBikeData.csv", stringsAsFactors = T)
?Bikeshare
bike.data <- Bikeshare
bike.data <- na.omit(bike.data)
bike.data <- Bikeshare
bike.data <- na.omit(bike.data)
library(ISLR2)
library(MASS)
library(pls)
View(bike.data)
bike.data <- Bikeshare
bike.data <- na.omit(bike.data[, -c(2,3)])
View(bike.data)
set.seed(2)
train <- sample(1:nrow(bike.data), nrow(bike.data) / 2)
test <- (-train)
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = forest.data, subset = train, scale = T,
validation = "CV")
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = bike.data, subset = train, scale = T,
validation = "CV")
set.seed(2)
train <- sample(1:nrow(bike.data), nrow(bike.data) / 2)
test <- (-train)
x <- model.matrix(bikers ~ ., bike.data)[, -13]
y <- bike.data$bikers
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = x, subset = train, scale = T,
validation = "CV")
# PCR
set.seed(1)
pcr.fit <- pcr(area ~ ., data = bike.data, subset = train, scale = T,
validation = "CV")
# PCR
set.seed(1)
pcr.fit <- pcr(bikers ~ ., data = bike.data, subset = train, scale = T,
validation = "CV")
bike.data$season <- as.factor(bike.data$season)
bike.data$workingday <- as.factor(bike.data$workingday)
bike.data$holiday <- as.factor(bike.data$holiday)
set.seed(2)
train <- sample(1:nrow(bike.data), nrow(bike.data) / 2)
test <- (-train)
x <- model.matrix(bikers ~ ., bike.data)[, -1]
y <- bike.data$bikers
# PCR
set.seed(1)
pcr.fit <- pcr(bikers ~ ., data = bike.data, subset = train, scale = T,
validation = "CV")
set.seed(2)
train <- sample(1:nrow(bike.data), nrow(bike.data) / 2)
test <- (-train)
x <- model.matrix(bikers ~ ., bike.data)[, -1]
y <- bike.data$bikers
bike.data <- bike.data[, 6:13]
set.seed(2)
train <- sample(1:nrow(bike.data), nrow(bike.data) / 2)
test <- (-train)
x <- model.matrix(bikers ~ ., bike.data)[, -1]
y <- bike.data$bikers
# PCR
set.seed(1)
pcr.fit <- pcr(bikers ~ ., data = bike.data, subset = train, scale = T,
validation = "CV")
bike.data <- bike.data[, 6:13]
bike.data <- Bikeshare
bike.data <- na.omit(bike.data[, -c(2,3)])
bike.data <- bike.data[, 6:13]
bike.data <- bike.data[, -5]
set.seed(2)
train <- sample(1:nrow(bike.data), nrow(bike.data) / 2)
test <- (-train)
x <- model.matrix(bikers ~ ., bike.data)[, -1]
y <- bike.data$bikers
# PCR
set.seed(1)
pcr.fit <- pcr(bikers ~ ., data = bike.data, subset = train, scale = T,
validation = "CV")
View(Hitters)
View(Credit)
?Credit
train <- sample(1:nrow(Credit), nrow(Credit) / 2)
test <- (-train)
set.seed(2)
pcr.fit <- pcr(Balance ~ ., data = Credit, subset = train, scale = T,
validation = "CV")
validationplot(pcr.fit, val.type = "MSEP")
axis(side=1, at=seq(1,20,by=1))
pcr.pred <- predict(pcr.fit, Credit[test, ], ncomp = 11)
pcr.mse <- mean((pcr.pred - Credit$Balance[test]))
pcr.mse
pcr.pred <- predict(pcr.fit, Credit[test, ], ncomp = 11)
pcr.mse <- mean((pcr.pred - Credit$Balance[test])^2)
pcr.mse
sqrt(pcr.mse)
cor(Credit)
lm.fit <- lm(Balance ~ ., data = Credit, subset = train)
lm.pred <- predict(lm.fit, Credit[test, ])
lm.mse <- ((lm.pred - Credit$Balance[test])^2)
lm.mse
lm.fit <- lm(Balance ~ ., data = Credit, subset = train)
lm.pred <- predict(lm.fit, Credit[test, ])
lm.mse <- mean((lm.pred - Credit$Balance[test])^2)
lm.mse
set.seed(2)
pcr.fit <- pcr(Balance ~ ., data = Credit, subset = train, scale = T,
validation = "CV")
summary(pcr.fit)
library(ISLR2)
library(MASS)
library(pls)
set.seed(1)
train <- sample(1:nrow(Credit), nrow(Credit) / 2)
test <- (-train)
set.seed(2)
pcr.fit <- pcr(Balance ~ ., data = Credit, subset = train, scale = T,
validation = "CV")
summary(pcr.fit)
validationplot(pcr.fit, val.type = "MSEP")
axis(side=1, at=seq(1,20,by=1))
